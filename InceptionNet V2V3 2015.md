#  InceptionNet V2/V3:2015

**Rethinking the Inception Architechture for Computer Vision**

**Google & College London**

#### 摘要

作者指出卷积神经网络已经在计算机视觉中的很多任务上表现优良，同时低参数量和网络的效率成为了卷积神经网络的发展方向，之后介绍了自己的工作，对比他们在ILSVRC2012提出的模型比较，通过集成新的Inception模块在数据集上面达到了3.5%的top5错误率和17.3%的top1错误率

#### 论文出发点或背景

虽然VGG提取特征的效果很好、结构简单，但是在计算时的消耗也非常大；GoogleNet就是为了在算力受限的平台上运行而发明的一种新的卷积神经网络架构。对比AlexNet，GoogLeNet只有十二分之一的参数量，而且VGG的参数时AlexNet的三倍。Inception模块的使用使得在内存或容量受限的设备中使用卷积神经网络进行视觉识别成为了可能。然而Inception模块的复杂性也导致了对网络进行修改是件很难的事情。同时GoogLeNe文章中也没有说清楚各种设计为什么是有效的，如果单纯增加网络的深度，单纯堆叠模块的话，有时候反倒会导致损失函数值上升。

在本文中首先阐述了几条一般性原则和优化思想，这些方法和原则被证明是扩展卷积网络的有效方法。

GoogLeNet在一大优点就是在计算的时候进行了降维，这可以被看作是以一种计算效率高的方式对卷积进行分解的一种特殊情况。

#### 论文创新思路

文章阐述的四个一般性原则：

1.在网络早期要避免网络的表征瓶颈，特征图的表示大小应该是从输入到输出逐渐减小的，应该避免极端压缩

2.高维表示在网络中更容易进行局部处理

3.低纬度嵌入聚合之后，对网络不会产生严重的不利影响，甚至还会促进更快的学习

4.好的网络应该能平衡网络每层上的深度和宽度，计算预算应该在网络的深度和宽度之间保持平衡的分布

卷积分解：

1.两个3×3卷积核的感受野可以和一个5×5的卷积核感受野对等，三个3×3可以和一个7×7的对等，通过这种将大卷积核分解为小卷积核可以减少网络的参数。网络的表达效果没有变差。

2.空间不对称卷积分解：小的卷积核也可以分解为更小的卷积核，比如3×3可以分解为2×2的，但是通过计算发现，如果将3×3卷积核不对称分解为1×3和3×1的卷积核会减少更多的参数。同时通过实验发现，这种分解在网络浅层的表现不是很好，但是在中等大小的特征图上面可以有很好的结果。

辅助分类器的使用：

1.发现辅助分类器在训练的早期并没有提高收敛性

2.去除辅助分类器之后发现对网络的精度没有太大的影响，辅助分类器可以被看作是一个正则化方式。

高效的空间降维方式

![image-20221115211752528](C:\Users\李鑫\AppData\Roaming\Typora\typora-user-images\image-20221115211752528.png)

标签平滑LSR：一种新的正则化方式

#### 论文方法的大概介绍

小卷积核等效为大卷积核

![image-20221115211916457](C:\Users\李鑫\AppData\Roaming\Typora\typora-user-images\image-20221115211916457.png)



非对称分解卷积核

![image-20221115212019045](C:\Users\李鑫\AppData\Roaming\Typora\typora-user-images\image-20221115212019045.png)

替换大卷积核后的模块

![image-20221115212041294](C:\Users\李鑫\AppData\Roaming\Typora\typora-user-images\image-20221115212041294.png)

![image-20221115212104172](C:\Users\李鑫\AppData\Roaming\Typora\typora-user-images\image-20221115212104172.png)

辅助分类器：

![image-20221115212121022](C:\Users\李鑫\AppData\Roaming\Typora\typora-user-images\image-20221115212121022.png)

![image-20221115212355937](C:\Users\李鑫\AppData\Roaming\Typora\typora-user-images\image-20221115212355937.png)

Inception V2 ：虽然有42层之深，但是网络的消耗只是GoogLeNet的2.5倍，并且比VGGNet更高效

部分参数配置：

![image-20221115212425890](C:\Users\李鑫\AppData\Roaming\Typora\typora-user-images\image-20221115212425890.png)

#### 实际效果

低分辨率输入情况下的模型性能：

![image-20221115212928736](C:\Users\李鑫\AppData\Roaming\Typora\typora-user-images\image-20221115212928736.png)

结果：虽然低分辨率的网络需要更长的训练时间，但是其最终结果的指标核高分辨率相当接近

![image-20221115213105416](C:\Users\李鑫\AppData\Roaming\Typora\typora-user-images\image-20221115213105416.png)

![image-20221115213140426](C:\Users\李鑫\AppData\Roaming\Typora\typora-user-images\image-20221115213140426.png)

![image-20221115213158376](C:\Users\李鑫\AppData\Roaming\Typora\typora-user-images\image-20221115213158376.png)

#### 个人理解

1.提出了四点设计网络结构时的原则

- 在网络早期要避免网络的表征瓶颈，特征图的表示大小应该是从输入到输出逐渐减小的，应该避免极端压缩
- 高维表示在网络中更容易进行局部处理
- 低纬度嵌入聚合之后，对网络不会产生严重的不利影响，甚至还会促进更快的学习
- 好的网络应该能平衡网络每层上的深度和宽度，计算预算应该在网络的深度和宽度之间保持平衡的分布

2.对卷积核进行分解，通过低秩进行近似，大大减少参数量

3.n×1和1×n卷积核可以看作是分别从宽度和长度上提取特征，就好像视频理解中P3D中对卷积进行时空上的拆解

4.提出了新的正则化方法：标签平滑